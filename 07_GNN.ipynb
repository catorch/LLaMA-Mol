{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>ECFP4_0</th>\n",
       "      <th>ECFP4_1</th>\n",
       "      <th>ECFP4_2</th>\n",
       "      <th>ECFP4_3</th>\n",
       "      <th>ECFP4_4</th>\n",
       "      <th>ECFP4_5</th>\n",
       "      <th>ECFP4_6</th>\n",
       "      <th>ECFP4_7</th>\n",
       "      <th>...</th>\n",
       "      <th>ECFP4_2038</th>\n",
       "      <th>ECFP4_2039</th>\n",
       "      <th>ECFP4_2040</th>\n",
       "      <th>ECFP4_2041</th>\n",
       "      <th>ECFP4_2042</th>\n",
       "      <th>ECFP4_2043</th>\n",
       "      <th>ECFP4_2044</th>\n",
       "      <th>ECFP4_2045</th>\n",
       "      <th>ECFP4_2046</th>\n",
       "      <th>ECFP4_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C(O)/C=C/c1ccc(OS(=O)(=O)O)cc1</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc(O)cc1</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCN(CCCN(CC)C(=O)c1ccc(O)cc1)C(=O)c1ccc(O)cc1</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc2cc(O)cc...</td>\n",
       "      <td>3.531653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCN(CCOC(=O)/C=C/c1ccc(O)cc1)Cc1cc(Cl)ccc1O</td>\n",
       "      <td>4.337242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    canonical_smiles     pIC50  ECFP4_0  \\\n",
       "0                   O=C(O)/C=C/c1ccc(OS(=O)(=O)O)cc1 -0.301030        0   \n",
       "1       CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc(O)cc1 -0.301030        0   \n",
       "2      CCN(CCCN(CC)C(=O)c1ccc(O)cc1)C(=O)c1ccc(O)cc1 -0.301030        0   \n",
       "3  CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc2cc(O)cc...  3.531653        0   \n",
       "4        CCN(CCOC(=O)/C=C/c1ccc(O)cc1)Cc1cc(Cl)ccc1O  4.337242        0   \n",
       "\n",
       "   ECFP4_1  ECFP4_2  ECFP4_3  ECFP4_4  ECFP4_5  ECFP4_6  ECFP4_7  ...  \\\n",
       "0        0        0        0        0        0        0        0  ...   \n",
       "1        0        0        0        0        0        0        0  ...   \n",
       "2        0        0        0        0        0        0        0  ...   \n",
       "3        0        0        0        0        0        0        0  ...   \n",
       "4        0        0        0        0        0        0        0  ...   \n",
       "\n",
       "   ECFP4_2038  ECFP4_2039  ECFP4_2040  ECFP4_2041  ECFP4_2042  ECFP4_2043  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   ECFP4_2044  ECFP4_2045  ECFP4_2046  ECFP4_2047  \n",
       "0           0           0           0           0  \n",
       "1           0           0           0           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 2050 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/target_molecules_clean_2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canonical_smiles     object\n",
       "pIC50               float64\n",
       "ECFP4_0               int64\n",
       "ECFP4_1               int64\n",
       "ECFP4_2               int64\n",
       "                     ...   \n",
       "ECFP4_2043            int64\n",
       "ECFP4_2044            int64\n",
       "ECFP4_2045            int64\n",
       "ECFP4_2046            int64\n",
       "ECFP4_2047            int64\n",
       "Length: 2050, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>ECFP4_0</th>\n",
       "      <th>ECFP4_1</th>\n",
       "      <th>ECFP4_2</th>\n",
       "      <th>ECFP4_3</th>\n",
       "      <th>ECFP4_4</th>\n",
       "      <th>ECFP4_5</th>\n",
       "      <th>ECFP4_6</th>\n",
       "      <th>ECFP4_7</th>\n",
       "      <th>...</th>\n",
       "      <th>ECFP4_2039</th>\n",
       "      <th>ECFP4_2040</th>\n",
       "      <th>ECFP4_2041</th>\n",
       "      <th>ECFP4_2042</th>\n",
       "      <th>ECFP4_2043</th>\n",
       "      <th>ECFP4_2044</th>\n",
       "      <th>ECFP4_2045</th>\n",
       "      <th>ECFP4_2046</th>\n",
       "      <th>ECFP4_2047</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C(O)/C=C/c1ccc(OS(=O)(=O)O)cc1</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc(O)cc1</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCN(CCCN(CC)C(=O)c1ccc(O)cc1)C(=O)c1ccc(O)cc1</td>\n",
       "      <td>-0.301030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc2cc(O)cc...</td>\n",
       "      <td>3.531653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCN(CCOC(=O)/C=C/c1ccc(O)cc1)Cc1cc(Cl)ccc1O</td>\n",
       "      <td>4.337242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    canonical_smiles     pIC50  ECFP4_0  \\\n",
       "0                   O=C(O)/C=C/c1ccc(OS(=O)(=O)O)cc1 -0.301030        0   \n",
       "1       CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc(O)cc1 -0.301030        0   \n",
       "2      CCN(CCCN(CC)C(=O)c1ccc(O)cc1)C(=O)c1ccc(O)cc1 -0.301030        0   \n",
       "3  CN(CCCNC(=O)c1ccc(O)cc1)CCCNC(=O)c1ccc2cc(O)cc...  3.531653        0   \n",
       "4        CCN(CCOC(=O)/C=C/c1ccc(O)cc1)Cc1cc(Cl)ccc1O  4.337242        0   \n",
       "\n",
       "   ECFP4_1  ECFP4_2  ECFP4_3  ECFP4_4  ECFP4_5  ECFP4_6  ECFP4_7  ...  \\\n",
       "0        0        0        0        0        0        0        0  ...   \n",
       "1        0        0        0        0        0        0        0  ...   \n",
       "2        0        0        0        0        0        0        0  ...   \n",
       "3        0        0        0        0        0        0        0  ...   \n",
       "4        0        0        0        0        0        0        0  ...   \n",
       "\n",
       "   ECFP4_2039  ECFP4_2040  ECFP4_2041  ECFP4_2042  ECFP4_2043  ECFP4_2044  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   ECFP4_2045  ECFP4_2046  ECFP4_2047  target  \n",
       "0           0           0           0       0  \n",
       "1           0           0           0       0  \n",
       "2           0           0           0       0  \n",
       "3           0           0           0       0  \n",
       "4           0           0           0       0  \n",
       "\n",
       "[5 rows x 2051 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary target column based on the condition pIC50 > 0.5\n",
    "df['target'] = (df['pIC50'] > 5.0).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Node features\n",
    "    atomic_nums = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
    "    chiralities = [atom.GetChiralTag() for atom in mol.GetAtoms()]\n",
    "    degrees = [atom.GetDegree() for atom in mol.GetAtoms()]\n",
    "    formal_charges = [atom.GetFormalCharge() for atom in mol.GetAtoms()]\n",
    "    num_hydrogens = [atom.GetTotalNumHs() for atom in mol.GetAtoms()]\n",
    "    num_radical_electrons = [atom.GetNumRadicalElectrons() for atom in mol.GetAtoms()]\n",
    "    hybridizations = [atom.GetHybridization() for atom in mol.GetAtoms()]\n",
    "    aromatics = [atom.GetIsAromatic() for atom in mol.GetAtoms()]\n",
    "    in_rings = [atom.IsInRing() for atom in mol.GetAtoms()]\n",
    "    \n",
    "    node_feats = list(zip(atomic_nums, chiralities, degrees, formal_charges, num_hydrogens, \n",
    "                          num_radical_electrons, hybridizations, aromatics, in_rings))\n",
    "    node_feats = torch.tensor(node_feats, dtype=torch.float)\n",
    "    \n",
    "    # Edges\n",
    "    edge_indices = []\n",
    "    bond_types = []\n",
    "    stereo_configs = []\n",
    "    is_conjugateds = []\n",
    "    for bond in mol.GetBonds():\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_indices.append((start, end))\n",
    "        edge_indices.append((end, start))  # Add both directions since the graph is undirected\n",
    "        bond_types.extend([bond.GetBondTypeAsDouble()] * 2)\n",
    "        stereo_configs.extend([bond.GetStereo()] * 2)\n",
    "        is_conjugateds.extend([bond.GetIsConjugated()] * 2)\n",
    "    \n",
    "    edge_feats = list(zip(bond_types, stereo_configs, is_conjugateds))\n",
    "    edge_feats = torch.tensor(edge_feats, dtype=torch.float)\n",
    "    edge_indices = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Create a PyG Data object\n",
    "    graph = Data(x=node_feats.to(device), edge_index=edge_indices.to(device), edge_attr=edge_feats.to(device))\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graphs = [smiles_to_graph(smiles) for smiles in df['canonical_smiles']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert the graphs and targets into lists for splitting\n",
    "graphs_list = list(graphs)\n",
    "targets_list = df['target'].tolist()\n",
    "\n",
    "# Split the data into train and temporary datasets (80% train, 20% temp)\n",
    "train_graphs, temp_graphs, train_targets, temp_targets = train_test_split(\n",
    "    graphs_list, targets_list, test_size=0.2, stratify=targets_list, random_state=42\n",
    ")\n",
    "\n",
    "# Split the temporary data into validation and test datasets (50% validation, 50% test)\n",
    "val_graphs, test_graphs, val_targets, test_targets = train_test_split(\n",
    "    temp_graphs, temp_targets, test_size=0.5, stratify=temp_targets, random_state=42\n",
    ")\n",
    "\n",
    "# Convert lists back to tensors for PyG compatibility\n",
    "train_targets = torch.tensor(train_targets, dtype=torch.long).to(device)\n",
    "val_targets = torch.tensor(val_targets, dtype=torch.long).to(device)\n",
    "test_targets = torch.tensor(test_targets, dtype=torch.long).to(device)\n",
    "\n",
    "# Add targets to graph data objects\n",
    "for graph, target in zip(train_graphs, train_targets):\n",
    "    graph.y = target\n",
    "\n",
    "for graph, target in zip(val_graphs, val_targets):\n",
    "    graph.y = target\n",
    "\n",
    "for graph, target in zip(test_graphs, test_targets):\n",
    "    graph.y = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9727e+00,  1.3139e-01,  9.9599e-01,  7.5892e-02,  2.9752e+00,\n",
       "          1.4274e-02,  4.0147e+00,  4.2812e-02,  8.5679e-02],\n",
       "        [ 8.3230e+00,  8.1465e-02,  1.9298e+00,  6.0213e-03, -6.1783e-02,\n",
       "          5.7997e-02,  3.0968e+00,  1.8527e-02,  8.0315e-02],\n",
       "        [ 6.1154e+00, -5.8172e-02,  2.9913e+00,  5.0748e-03,  1.5648e-01,\n",
       "         -6.2758e-02,  2.9067e+00,  8.2520e-01,  1.0647e+00],\n",
       "        [ 5.9746e+00,  4.6717e-02,  1.7104e+00,  1.9432e-01,  9.9301e-01,\n",
       "          1.2092e-01,  3.0078e+00,  1.0253e+00,  1.0054e+00],\n",
       "        [ 5.8330e+00, -4.3671e-02,  2.0335e+00,  9.8586e-02,  9.9091e-01,\n",
       "         -1.5921e-02,  2.9736e+00,  9.8785e-01,  9.5788e-01]], device='cuda:1')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the AddGaussianNoise transform\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0, std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if data.x is not None:\n",
    "            data.x = data.x + torch.randn_like(data.x) * self.std + self.mean\n",
    "        return data\n",
    "\n",
    "# Instantiate the transform\n",
    "add_gaussian_noise = AddGaussianNoise(mean=0, std=0.1)\n",
    "\n",
    "# Apply the transform to each graph in the training set\n",
    "train_graphs_transformed = [add_gaussian_noise(graph) for graph in train_graphs]\n",
    "\n",
    "# Check the first graph's features to see if noise is added\n",
    "train_graphs_transformed[0].x[:5]  # Displaying the first 5 nodes' features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9727e+00,  1.3139e-01,  9.9599e-01,  0.0000e+00,  2.9752e+00,\n",
       "          1.4274e-02,  4.0147e+00,  4.2812e-02,  8.5679e-02],\n",
       "        [ 8.3230e+00,  8.1465e-02,  1.9298e+00,  0.0000e+00, -6.1783e-02,\n",
       "          5.7997e-02,  3.0968e+00,  1.8527e-02,  8.0315e-02],\n",
       "        [ 6.1154e+00, -5.8172e-02,  2.9913e+00,  0.0000e+00,  1.5648e-01,\n",
       "         -6.2758e-02,  2.9067e+00,  8.2520e-01,  1.0647e+00],\n",
       "        [ 5.9746e+00,  4.6717e-02,  1.7104e+00,  0.0000e+00,  9.9301e-01,\n",
       "          1.2092e-01,  3.0078e+00,  1.0253e+00,  1.0054e+00],\n",
       "        [ 5.8330e+00, -4.3671e-02,  2.0335e+00,  0.0000e+00,  9.9091e-01,\n",
       "         -1.5921e-02,  2.9736e+00,  9.8785e-01,  9.5788e-01],\n",
       "        [ 5.8137e+00,  1.7382e-01,  2.9669e+00,  0.0000e+00,  4.8954e-02,\n",
       "          1.0035e-01,  2.9630e+00,  1.0520e+00,  1.0472e+00],\n",
       "        [ 6.1809e+00, -1.6178e-01,  3.0157e+00,  0.0000e+00, -4.5318e-02,\n",
       "          9.2799e-02,  2.9223e+00,  1.2094e+00,  9.1527e-01],\n",
       "        [ 5.9831e+00, -4.4775e-02,  1.9796e+00,  0.0000e+00,  8.4404e-01,\n",
       "          4.8299e-02,  2.9500e+00,  9.4251e-01,  9.3738e-01],\n",
       "        [ 6.2194e+00, -1.1638e-01,  3.0743e+00,  0.0000e+00,  5.4988e-02,\n",
       "          1.0472e-01,  3.0469e+00,  7.7316e-01,  1.0720e+00],\n",
       "        [ 7.0802e+00, -6.1573e-02,  1.8609e+00,  0.0000e+00, -1.4714e-02,\n",
       "         -2.6051e-02,  2.9710e+00,  7.9370e-01,  1.1752e+00],\n",
       "        [ 5.9408e+00, -1.4781e-01,  3.0069e+00,  0.0000e+00,  1.7014e-01,\n",
       "          5.8885e-03,  3.1085e+00,  1.0340e+00,  9.9939e-01],\n",
       "        [ 7.0823e+00, -3.9484e-02,  1.9534e+00,  0.0000e+00,  1.0692e-01,\n",
       "          8.3601e-02,  2.7612e+00, -1.9259e-01,  6.5326e-02],\n",
       "        [ 6.0607e+00,  1.3543e-01,  1.9899e+00,  0.0000e+00,  9.9680e-01,\n",
       "         -1.1881e-01,  3.0411e+00, -1.0663e-01,  2.0100e-02],\n",
       "        [ 6.0515e+00,  2.8736e-02,  3.0763e+00,  0.0000e+00,  1.9774e-02,\n",
       "         -1.0378e-01,  3.0224e+00,  8.4278e-01,  1.1039e+00],\n",
       "        [ 5.8933e+00, -8.8910e-02,  3.0265e+00,  0.0000e+00,  5.0587e-02,\n",
       "          1.8326e-02,  2.8986e+00,  8.9998e-01,  1.1368e+00],\n",
       "        [ 8.0995e+00, -7.2964e-02,  9.2058e-01,  0.0000e+00,  9.8139e-01,\n",
       "          9.3132e-02,  2.7948e+00,  9.3327e-03,  6.9940e-02],\n",
       "        [ 6.0205e+00,  3.9977e-02,  1.9002e+00,  0.0000e+00,  1.1100e+00,\n",
       "         -5.5329e-02,  2.9947e+00,  9.3183e-01,  9.1050e-01],\n",
       "        [ 6.0727e+00, -2.1367e-01,  2.0565e+00,  0.0000e+00,  1.0212e+00,\n",
       "          9.0801e-02,  3.1312e+00,  8.5875e-01,  1.0960e+00],\n",
       "        [ 5.7549e+00,  8.7369e-02,  3.0234e+00,  0.0000e+00,  1.0861e-01,\n",
       "          1.0610e-01,  2.9947e+00,  9.4639e-01,  1.0396e+00],\n",
       "        [ 6.0485e+00, -1.7590e-02,  2.1007e+00,  0.0000e+00,  9.8616e-01,\n",
       "         -6.5116e-03,  2.8323e+00,  1.0447e+00,  9.6374e-01],\n",
       "        [ 6.0905e+00, -1.5909e-02,  2.1420e+00,  0.0000e+00,  9.1682e-01,\n",
       "         -6.3834e-02,  2.9159e+00,  1.0067e+00,  9.4684e-01],\n",
       "        [ 6.0362e+00,  1.9579e-03,  2.0533e+00,  0.0000e+00,  8.6693e-01,\n",
       "          6.2091e-02,  3.0317e+00,  1.3337e+00,  9.3299e-01],\n",
       "        [ 5.9646e+00,  6.3339e-02,  2.1084e+00,  0.0000e+00,  1.0386e+00,\n",
       "          1.4582e-01,  2.8761e+00,  8.6172e-01,  1.0198e+00],\n",
       "        [ 6.1371e+00, -1.1540e-01,  2.8879e+00,  0.0000e+00,  6.8789e-04,\n",
       "          4.1492e-02,  3.0164e+00,  8.5969e-01,  9.3894e-01],\n",
       "        [ 1.5955e+01,  1.4979e-01,  2.0477e+00,  0.0000e+00,  2.0590e-01,\n",
       "          1.0441e-01,  3.0420e+00,  1.0757e+00,  8.8453e-01],\n",
       "        [ 5.9763e+00, -4.5398e-02,  3.0508e+00,  0.0000e+00,  4.0517e-02,\n",
       "         -5.5943e-02,  2.9772e+00,  9.9187e-01,  9.7452e-01],\n",
       "        [ 5.9538e+00,  1.2387e-02,  2.0933e+00,  0.0000e+00,  2.1235e+00,\n",
       "         -8.1003e-02,  4.0326e+00, -1.6373e-02,  1.1544e+00],\n",
       "        [ 5.9915e+00, -6.7566e-02,  1.9979e+00,  0.0000e+00,  2.0080e+00,\n",
       "          2.0659e-01,  3.9487e+00,  5.8912e-03,  9.3951e-01]], device='cuda:1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the FeatureDropout transform\n",
    "class FeatureDropout(object):\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Check if input data has a `x` attribute\n",
    "        if data.x is not None:\n",
    "            # Randomly dropout features with probability `p`\n",
    "            mask = torch.rand(data.x.shape[1]) < self.p\n",
    "            data.x[:, mask] = 0\n",
    "        \n",
    "        return data\n",
    "\n",
    "# Apply the FeatureDropout transform to the training graphs\n",
    "feature_dropout_transform = FeatureDropout(p=0.05)\n",
    "train_graphs_transformed = [feature_dropout_transform(graph) for graph in train_graphs]\n",
    "\n",
    "# Let's check the effect of the transformation on the first graph's node features\n",
    "train_graphs_transformed[0].x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "# Create PyTorch Geometric DataLoaders\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_node_features, input_edge_features, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        # Define the convolution layers\n",
    "        self.conv1 = GCNConv(input_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # Define the final classifier\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        # 1. Node embedding \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 2. Readout layer\n",
    "        batch = torch.zeros(x.shape[0], dtype=int).to(device) if batch is None else batch\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # 3. Final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = GNN(input_node_features=9, input_edge_features=3, hidden_channels=64).to(device)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6961, 1.7750], device='cuda:1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate class weights\n",
    "num_pos = sum(targets_list)  \n",
    "num_neg = len(targets_list) - num_pos\n",
    "total_samples = len(targets_list)\n",
    "\n",
    "weight_class1 = total_samples / (2 * num_pos)\n",
    "weight_class0 = total_samples / (2 * num_neg)\n",
    "\n",
    "weights = torch.tensor([weight_class0, weight_class1]).to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/512 | Train Loss: 0.6591 | Train Accuracy: 0.6669 | Validation Accuracy: 0.7372\n",
      "Epoch 20/512 | Train Loss: 0.6365 | Train Accuracy: 0.7326 | Validation Accuracy: 0.7436\n",
      "Epoch 30/512 | Train Loss: 0.6367 | Train Accuracy: 0.7382 | Validation Accuracy: 0.7628\n",
      "Epoch 40/512 | Train Loss: 0.6148 | Train Accuracy: 0.7574 | Validation Accuracy: 0.7692\n",
      "Epoch 50/512 | Train Loss: 0.6153 | Train Accuracy: 0.7262 | Validation Accuracy: 0.7628\n",
      "Epoch 60/512 | Train Loss: 0.6108 | Train Accuracy: 0.7566 | Validation Accuracy: 0.7949\n",
      "Epoch 70/512 | Train Loss: 0.6038 | Train Accuracy: 0.7454 | Validation Accuracy: 0.7500\n",
      "Epoch 80/512 | Train Loss: 0.5722 | Train Accuracy: 0.7654 | Validation Accuracy: 0.7628\n",
      "Epoch 90/512 | Train Loss: 0.6295 | Train Accuracy: 0.7558 | Validation Accuracy: 0.7756\n",
      "Epoch 100/512 | Train Loss: 0.5754 | Train Accuracy: 0.7646 | Validation Accuracy: 0.7500\n",
      "Epoch 110/512 | Train Loss: 0.5698 | Train Accuracy: 0.7598 | Validation Accuracy: 0.7500\n",
      "Epoch 120/512 | Train Loss: 0.5507 | Train Accuracy: 0.7614 | Validation Accuracy: 0.7692\n",
      "Epoch 130/512 | Train Loss: 0.5365 | Train Accuracy: 0.7366 | Validation Accuracy: 0.7436\n",
      "Epoch 140/512 | Train Loss: 0.5602 | Train Accuracy: 0.7494 | Validation Accuracy: 0.7756\n",
      "Epoch 150/512 | Train Loss: 0.5464 | Train Accuracy: 0.7782 | Validation Accuracy: 0.7756\n",
      "Epoch 160/512 | Train Loss: 0.5437 | Train Accuracy: 0.7262 | Validation Accuracy: 0.7372\n",
      "Epoch 170/512 | Train Loss: 0.5432 | Train Accuracy: 0.7350 | Validation Accuracy: 0.7179\n",
      "Epoch 180/512 | Train Loss: 0.5522 | Train Accuracy: 0.6998 | Validation Accuracy: 0.7308\n",
      "Epoch 190/512 | Train Loss: 0.5237 | Train Accuracy: 0.7558 | Validation Accuracy: 0.7244\n",
      "Epoch 200/512 | Train Loss: 0.5449 | Train Accuracy: 0.7254 | Validation Accuracy: 0.7115\n",
      "Epoch 210/512 | Train Loss: 0.5287 | Train Accuracy: 0.7374 | Validation Accuracy: 0.7051\n",
      "Epoch 220/512 | Train Loss: 0.5217 | Train Accuracy: 0.7158 | Validation Accuracy: 0.7308\n",
      "Epoch 230/512 | Train Loss: 0.4986 | Train Accuracy: 0.7342 | Validation Accuracy: 0.7244\n",
      "Epoch 240/512 | Train Loss: 0.5017 | Train Accuracy: 0.7262 | Validation Accuracy: 0.6795\n",
      "Epoch 250/512 | Train Loss: 0.5253 | Train Accuracy: 0.7454 | Validation Accuracy: 0.7051\n",
      "Epoch 260/512 | Train Loss: 0.5190 | Train Accuracy: 0.7246 | Validation Accuracy: 0.7308\n",
      "Epoch 270/512 | Train Loss: 0.5007 | Train Accuracy: 0.7334 | Validation Accuracy: 0.6859\n",
      "Epoch 280/512 | Train Loss: 0.5013 | Train Accuracy: 0.7270 | Validation Accuracy: 0.6859\n",
      "Epoch 290/512 | Train Loss: 0.5095 | Train Accuracy: 0.7230 | Validation Accuracy: 0.6795\n",
      "Epoch 300/512 | Train Loss: 0.5081 | Train Accuracy: 0.7510 | Validation Accuracy: 0.6731\n",
      "Epoch 310/512 | Train Loss: 0.4722 | Train Accuracy: 0.7446 | Validation Accuracy: 0.7115\n",
      "Epoch 320/512 | Train Loss: 0.5935 | Train Accuracy: 0.6397 | Validation Accuracy: 0.7756\n",
      "Epoch 330/512 | Train Loss: 0.4890 | Train Accuracy: 0.7398 | Validation Accuracy: 0.6603\n",
      "Epoch 340/512 | Train Loss: 0.5071 | Train Accuracy: 0.7286 | Validation Accuracy: 0.6603\n",
      "Epoch 350/512 | Train Loss: 0.5259 | Train Accuracy: 0.7206 | Validation Accuracy: 0.7051\n",
      "Epoch 360/512 | Train Loss: 0.5033 | Train Accuracy: 0.7558 | Validation Accuracy: 0.6603\n",
      "Epoch 370/512 | Train Loss: 0.4851 | Train Accuracy: 0.7406 | Validation Accuracy: 0.5962\n",
      "Epoch 380/512 | Train Loss: 0.4914 | Train Accuracy: 0.7510 | Validation Accuracy: 0.6795\n",
      "Epoch 390/512 | Train Loss: 0.4895 | Train Accuracy: 0.7398 | Validation Accuracy: 0.6731\n",
      "Epoch 400/512 | Train Loss: 0.4768 | Train Accuracy: 0.7318 | Validation Accuracy: 0.6923\n",
      "Epoch 410/512 | Train Loss: 0.4971 | Train Accuracy: 0.7318 | Validation Accuracy: 0.6603\n",
      "Epoch 420/512 | Train Loss: 0.5217 | Train Accuracy: 0.7294 | Validation Accuracy: 0.6859\n",
      "Epoch 430/512 | Train Loss: 0.5904 | Train Accuracy: 0.6301 | Validation Accuracy: 0.6282\n",
      "Epoch 440/512 | Train Loss: 0.5589 | Train Accuracy: 0.6541 | Validation Accuracy: 0.6410\n",
      "Epoch 450/512 | Train Loss: 0.5137 | Train Accuracy: 0.7486 | Validation Accuracy: 0.6667\n",
      "Epoch 460/512 | Train Loss: 0.5107 | Train Accuracy: 0.7086 | Validation Accuracy: 0.6282\n",
      "Epoch 470/512 | Train Loss: 0.4950 | Train Accuracy: 0.7222 | Validation Accuracy: 0.6538\n",
      "Epoch 480/512 | Train Loss: 0.5050 | Train Accuracy: 0.7174 | Validation Accuracy: 0.6667\n",
      "Epoch 490/512 | Train Loss: 0.4894 | Train Accuracy: 0.7350 | Validation Accuracy: 0.6795\n",
      "Epoch 500/512 | Train Loss: 0.4820 | Train Accuracy: 0.7310 | Validation Accuracy: 0.6282\n",
      "Epoch 510/512 | Train Loss: 0.5174 | Train Accuracy: 0.7366 | Validation Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# model = GNN(num_node_features=1, num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0  # Track total number of samples processed\n",
    "    \n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)  # Pass the batch attribute\n",
    "        \n",
    "        loss = loss_func(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        pred = out.argmax(dim=1)  # Get the class with the maximum probability\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)  # Add the size of the current batch to the total\n",
    "\n",
    "    train_acc = correct / total\n",
    "    return total_loss / len(train_loader), train_acc\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0  # Track total number of samples processed\n",
    "    \n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            pred = out.argmax(dim=1)  # Get the class with the maximum probability\n",
    "\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)  # Add the size of the current batch to the total\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "epochs = 512\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train() \n",
    "    val_acc = validate()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc >= 0.85:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7771 | Recall: 0.8636 | Precision: 0.5672 | F1 Score: 0.6847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def test_metrics():\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            preds = out.argmax(dim=1).tolist()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(data.y.tolist())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return acc, recall, precision, f1\n",
    "\n",
    "# At the end of training or wherever you want to print the metrics:\n",
    "acc, recall, precision, f1 = test_metrics()\n",
    "print(f\"Test Accuracy: {acc:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.NNConv.html\n",
    "class EdgeNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeNetwork, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin(x))\n",
    "        return x\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_node_features, input_edge_features, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        # Define the edge update network for NNConv\n",
    "        edge_nn1 = EdgeNetwork(input_edge_features, input_node_features * hidden_channels)\n",
    "        self.conv1 = NNConv(input_node_features, hidden_channels, edge_nn1)\n",
    "        \n",
    "        edge_nn2 = EdgeNetwork(input_edge_features, hidden_channels * hidden_channels)\n",
    "        self.conv2 = NNConv(hidden_channels, hidden_channels, edge_nn2)\n",
    "        \n",
    "        # Define the final classifier\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        # 1. Node embedding with edge features\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 2. Readout layer\n",
    "        batch = torch.zeros(x.shape[0], dtype=int).to(device) if batch is None else batch\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # 3. Final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = GNN(input_node_features=9, input_edge_features=3, hidden_channels=64).to(device)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/512 | Train Loss: 0.6166 | Train Accuracy: 0.7182 | Validation Accuracy: 0.7436\n",
      "Epoch 20/512 | Train Loss: 0.6025 | Train Accuracy: 0.7078 | Validation Accuracy: 0.7949\n",
      "Epoch 30/512 | Train Loss: 0.5839 | Train Accuracy: 0.7246 | Validation Accuracy: 0.6410\n",
      "Epoch 40/512 | Train Loss: 0.5914 | Train Accuracy: 0.6910 | Validation Accuracy: 0.7051\n",
      "Epoch 50/512 | Train Loss: 0.5664 | Train Accuracy: 0.7294 | Validation Accuracy: 0.7564\n",
      "Epoch 60/512 | Train Loss: 0.5476 | Train Accuracy: 0.7494 | Validation Accuracy: 0.7628\n",
      "Epoch 70/512 | Train Loss: 0.5430 | Train Accuracy: 0.7406 | Validation Accuracy: 0.7115\n",
      "Epoch 80/512 | Train Loss: 0.5100 | Train Accuracy: 0.7646 | Validation Accuracy: 0.6346\n",
      "Epoch 90/512 | Train Loss: 0.5143 | Train Accuracy: 0.7606 | Validation Accuracy: 0.7756\n",
      "Epoch 100/512 | Train Loss: 0.5077 | Train Accuracy: 0.7430 | Validation Accuracy: 0.7244\n",
      "Epoch 110/512 | Train Loss: 0.5055 | Train Accuracy: 0.7710 | Validation Accuracy: 0.7564\n",
      "Epoch 120/512 | Train Loss: 0.4992 | Train Accuracy: 0.7478 | Validation Accuracy: 0.6923\n",
      "Epoch 130/512 | Train Loss: 0.4672 | Train Accuracy: 0.7718 | Validation Accuracy: 0.7821\n",
      "Epoch 140/512 | Train Loss: 0.4679 | Train Accuracy: 0.7918 | Validation Accuracy: 0.7692\n",
      "Epoch 150/512 | Train Loss: 0.4446 | Train Accuracy: 0.7710 | Validation Accuracy: 0.7564\n",
      "Epoch 160/512 | Train Loss: 0.4292 | Train Accuracy: 0.8030 | Validation Accuracy: 0.7628\n",
      "Epoch 170/512 | Train Loss: 0.4256 | Train Accuracy: 0.7878 | Validation Accuracy: 0.7372\n",
      "Epoch 180/512 | Train Loss: 0.5145 | Train Accuracy: 0.7758 | Validation Accuracy: 0.6474\n",
      "Epoch 190/512 | Train Loss: 0.4385 | Train Accuracy: 0.7958 | Validation Accuracy: 0.6603\n",
      "Epoch 200/512 | Train Loss: 0.4148 | Train Accuracy: 0.8038 | Validation Accuracy: 0.7436\n",
      "Epoch 210/512 | Train Loss: 0.4056 | Train Accuracy: 0.8183 | Validation Accuracy: 0.7564\n",
      "Epoch 220/512 | Train Loss: 0.4150 | Train Accuracy: 0.7926 | Validation Accuracy: 0.6603\n",
      "Epoch 230/512 | Train Loss: 0.3877 | Train Accuracy: 0.8118 | Validation Accuracy: 0.7372\n",
      "Epoch 240/512 | Train Loss: 0.3910 | Train Accuracy: 0.8143 | Validation Accuracy: 0.7885\n",
      "Epoch 250/512 | Train Loss: 0.4261 | Train Accuracy: 0.7942 | Validation Accuracy: 0.7372\n",
      "Epoch 260/512 | Train Loss: 0.3639 | Train Accuracy: 0.8183 | Validation Accuracy: 0.7500\n",
      "Epoch 270/512 | Train Loss: 0.3615 | Train Accuracy: 0.8439 | Validation Accuracy: 0.7372\n",
      "Epoch 280/512 | Train Loss: 0.3740 | Train Accuracy: 0.8207 | Validation Accuracy: 0.7436\n",
      "Epoch 290/512 | Train Loss: 0.6265 | Train Accuracy: 0.7630 | Validation Accuracy: 0.6731\n",
      "Epoch 300/512 | Train Loss: 0.4144 | Train Accuracy: 0.7662 | Validation Accuracy: 0.6859\n",
      "Epoch 310/512 | Train Loss: 0.3693 | Train Accuracy: 0.7990 | Validation Accuracy: 0.6923\n",
      "Epoch 320/512 | Train Loss: 0.3559 | Train Accuracy: 0.8167 | Validation Accuracy: 0.6987\n",
      "Epoch 330/512 | Train Loss: 0.3478 | Train Accuracy: 0.8006 | Validation Accuracy: 0.7372\n",
      "Epoch 340/512 | Train Loss: 0.4739 | Train Accuracy: 0.7854 | Validation Accuracy: 0.6410\n",
      "Epoch 350/512 | Train Loss: 0.3436 | Train Accuracy: 0.8231 | Validation Accuracy: 0.7179\n",
      "Epoch 360/512 | Train Loss: 0.3553 | Train Accuracy: 0.8070 | Validation Accuracy: 0.7244\n",
      "Epoch 370/512 | Train Loss: 0.3238 | Train Accuracy: 0.8311 | Validation Accuracy: 0.6731\n",
      "Epoch 380/512 | Train Loss: 0.3255 | Train Accuracy: 0.8327 | Validation Accuracy: 0.7115\n",
      "Epoch 390/512 | Train Loss: 0.4149 | Train Accuracy: 0.8247 | Validation Accuracy: 0.6026\n",
      "Epoch 400/512 | Train Loss: 0.3260 | Train Accuracy: 0.8287 | Validation Accuracy: 0.5897\n",
      "Epoch 410/512 | Train Loss: 0.3533 | Train Accuracy: 0.8247 | Validation Accuracy: 0.7436\n",
      "Epoch 420/512 | Train Loss: 0.3247 | Train Accuracy: 0.8263 | Validation Accuracy: 0.7051\n",
      "Epoch 430/512 | Train Loss: 0.3127 | Train Accuracy: 0.8439 | Validation Accuracy: 0.6538\n",
      "Epoch 440/512 | Train Loss: 0.3362 | Train Accuracy: 0.8391 | Validation Accuracy: 0.6282\n",
      "Epoch 450/512 | Train Loss: 0.4329 | Train Accuracy: 0.7822 | Validation Accuracy: 0.6474\n",
      "Epoch 460/512 | Train Loss: 0.3466 | Train Accuracy: 0.8327 | Validation Accuracy: 0.7436\n",
      "Epoch 470/512 | Train Loss: 0.3505 | Train Accuracy: 0.7790 | Validation Accuracy: 0.5897\n",
      "Epoch 480/512 | Train Loss: 0.2972 | Train Accuracy: 0.8607 | Validation Accuracy: 0.6346\n",
      "Epoch 490/512 | Train Loss: 0.3741 | Train Accuracy: 0.8415 | Validation Accuracy: 0.7628\n",
      "Epoch 500/512 | Train Loss: 0.3460 | Train Accuracy: 0.8159 | Validation Accuracy: 0.7051\n",
      "Epoch 510/512 | Train Loss: 0.4084 | Train Accuracy: 0.8022 | Validation Accuracy: 0.5705\n"
     ]
    }
   ],
   "source": [
    "# model = GNN(num_node_features=1, num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0  # Track total number of samples processed\n",
    "    \n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)  # Pass the batch attribute\n",
    "        \n",
    "        loss = loss_func(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        pred = out.argmax(dim=1)  # Get the class with the maximum probability\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)  # Add the size of the current batch to the total\n",
    "\n",
    "    train_acc = correct / total\n",
    "    return total_loss / len(train_loader), train_acc\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0  # Track total number of samples processed\n",
    "    \n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            pred = out.argmax(dim=1)  # Get the class with the maximum probability\n",
    "\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)  # Add the size of the current batch to the total\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "epochs = 512\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train() \n",
    "    val_acc = validate()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f} | Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7197 | Recall: 0.8409 | Precision: 0.5000 | F1 Score: 0.6271\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def test_metrics():\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            preds = out.argmax(dim=1).tolist()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(data.y.tolist())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return acc, recall, precision, f1\n",
    "\n",
    "# At the end of training or wherever you want to print the metrics:\n",
    "acc, recall, precision, f1 = test_metrics()\n",
    "print(f\"Test Accuracy: {acc:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "\n",
    "class CustomGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_features):\n",
    "        super(CustomGCNConv, self).__init__(aggr='add')  # \"Add\" aggregation\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.edge_nn = torch.nn.Linear(edge_features, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Transform node inputs\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Transform edge inputs\n",
    "        edge_attr = self.edge_nn(edge_attr)\n",
    "\n",
    "        # Start message passing\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Combine node and edge features in message function\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Update node features with aggregated values\n",
    "        return aggr_out\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_node_features, input_edge_features, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        # Define the convolution layers\n",
    "        self.conv1 = CustomGCNConv(input_node_features, hidden_channels, input_edge_features)\n",
    "        self.conv2 = CustomGCNConv(hidden_channels, hidden_channels, input_edge_features)\n",
    "        \n",
    "        # Define the final classifier\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
    "        # 1. Node embedding \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 2. Readout layer\n",
    "        batch = torch.zeros(x.shape[0], dtype=int).to(device) if batch is None else batch\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # 3. Final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = GNN(input_node_features=9, input_edge_features=3, hidden_channels=64).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/512 | Train Loss: 0.6957 | Train Accuracy: 0.4043 | Validation Accuracy: 0.2821\n",
      "Epoch 20/512 | Train Loss: 0.6617 | Train Accuracy: 0.4988 | Validation Accuracy: 0.4872\n",
      "Epoch 30/512 | Train Loss: 0.6815 | Train Accuracy: 0.5140 | Validation Accuracy: 0.6603\n",
      "Epoch 40/512 | Train Loss: 0.6198 | Train Accuracy: 0.6125 | Validation Accuracy: 0.5962\n",
      "Epoch 50/512 | Train Loss: 0.6036 | Train Accuracy: 0.7574 | Validation Accuracy: 0.7564\n",
      "Epoch 60/512 | Train Loss: 0.5994 | Train Accuracy: 0.7718 | Validation Accuracy: 0.7821\n",
      "Epoch 70/512 | Train Loss: 0.5810 | Train Accuracy: 0.7966 | Validation Accuracy: 0.7949\n",
      "Epoch 80/512 | Train Loss: 0.5760 | Train Accuracy: 0.7902 | Validation Accuracy: 0.8013\n",
      "Epoch 90/512 | Train Loss: 0.5747 | Train Accuracy: 0.7878 | Validation Accuracy: 0.7885\n",
      "Epoch 100/512 | Train Loss: 0.5687 | Train Accuracy: 0.8038 | Validation Accuracy: 0.8077\n",
      "Epoch 110/512 | Train Loss: 0.5784 | Train Accuracy: 0.7878 | Validation Accuracy: 0.7885\n",
      "Epoch 120/512 | Train Loss: 0.5524 | Train Accuracy: 0.7918 | Validation Accuracy: 0.8013\n",
      "Epoch 130/512 | Train Loss: 0.5576 | Train Accuracy: 0.7622 | Validation Accuracy: 0.8141\n",
      "Epoch 140/512 | Train Loss: 0.6030 | Train Accuracy: 0.6934 | Validation Accuracy: 0.6795\n",
      "Epoch 150/512 | Train Loss: 0.5297 | Train Accuracy: 0.7358 | Validation Accuracy: 0.7628\n",
      "Epoch 160/512 | Train Loss: 0.5440 | Train Accuracy: 0.7822 | Validation Accuracy: 0.7885\n",
      "Epoch 170/512 | Train Loss: 0.5270 | Train Accuracy: 0.7934 | Validation Accuracy: 0.8077\n",
      "Epoch 180/512 | Train Loss: 0.5384 | Train Accuracy: 0.6805 | Validation Accuracy: 0.6923\n",
      "Epoch 190/512 | Train Loss: 0.5629 | Train Accuracy: 0.7630 | Validation Accuracy: 0.6603\n",
      "Epoch 200/512 | Train Loss: 0.5137 | Train Accuracy: 0.7334 | Validation Accuracy: 0.7500\n",
      "Epoch 210/512 | Train Loss: 0.5352 | Train Accuracy: 0.7790 | Validation Accuracy: 0.8077\n",
      "Epoch 220/512 | Train Loss: 0.4934 | Train Accuracy: 0.8102 | Validation Accuracy: 0.8013\n",
      "Epoch 230/512 | Train Loss: 0.5107 | Train Accuracy: 0.8110 | Validation Accuracy: 0.8013\n",
      "Epoch 240/512 | Train Loss: 0.4985 | Train Accuracy: 0.8054 | Validation Accuracy: 0.8141\n",
      "Epoch 250/512 | Train Loss: 0.5037 | Train Accuracy: 0.7702 | Validation Accuracy: 0.7949\n",
      "Epoch 260/512 | Train Loss: 0.4754 | Train Accuracy: 0.7942 | Validation Accuracy: 0.8077\n",
      "Epoch 270/512 | Train Loss: 0.5077 | Train Accuracy: 0.8151 | Validation Accuracy: 0.8077\n",
      "Epoch 280/512 | Train Loss: 0.5191 | Train Accuracy: 0.7158 | Validation Accuracy: 0.6859\n",
      "Epoch 290/512 | Train Loss: 0.5889 | Train Accuracy: 0.7390 | Validation Accuracy: 0.7949\n",
      "Epoch 300/512 | Train Loss: 0.4643 | Train Accuracy: 0.7374 | Validation Accuracy: 0.7308\n",
      "Epoch 310/512 | Train Loss: 0.4832 | Train Accuracy: 0.7670 | Validation Accuracy: 0.6923\n",
      "Epoch 320/512 | Train Loss: 0.5008 | Train Accuracy: 0.7158 | Validation Accuracy: 0.6731\n",
      "Epoch 330/512 | Train Loss: 0.5009 | Train Accuracy: 0.8215 | Validation Accuracy: 0.8077\n",
      "Epoch 340/512 | Train Loss: 0.5209 | Train Accuracy: 0.8175 | Validation Accuracy: 0.8077\n",
      "Epoch 350/512 | Train Loss: 0.4441 | Train Accuracy: 0.7614 | Validation Accuracy: 0.8013\n",
      "Epoch 360/512 | Train Loss: 0.4843 | Train Accuracy: 0.8143 | Validation Accuracy: 0.8013\n",
      "Epoch 370/512 | Train Loss: 0.4508 | Train Accuracy: 0.8143 | Validation Accuracy: 0.7949\n",
      "Epoch 380/512 | Train Loss: 0.4423 | Train Accuracy: 0.8255 | Validation Accuracy: 0.7564\n",
      "Epoch 390/512 | Train Loss: 0.5043 | Train Accuracy: 0.7502 | Validation Accuracy: 0.7179\n",
      "Epoch 400/512 | Train Loss: 0.4596 | Train Accuracy: 0.8183 | Validation Accuracy: 0.8077\n",
      "Epoch 410/512 | Train Loss: 0.4510 | Train Accuracy: 0.7950 | Validation Accuracy: 0.8013\n",
      "Epoch 420/512 | Train Loss: 0.4905 | Train Accuracy: 0.8118 | Validation Accuracy: 0.7885\n",
      "Epoch 430/512 | Train Loss: 0.4401 | Train Accuracy: 0.7998 | Validation Accuracy: 0.7115\n",
      "Epoch 440/512 | Train Loss: 0.4535 | Train Accuracy: 0.8279 | Validation Accuracy: 0.8077\n",
      "Epoch 450/512 | Train Loss: 0.4479 | Train Accuracy: 0.8078 | Validation Accuracy: 0.7821\n",
      "Epoch 460/512 | Train Loss: 0.4588 | Train Accuracy: 0.7470 | Validation Accuracy: 0.6859\n",
      "Epoch 470/512 | Train Loss: 0.4303 | Train Accuracy: 0.8255 | Validation Accuracy: 0.7885\n",
      "Epoch 480/512 | Train Loss: 0.4372 | Train Accuracy: 0.7854 | Validation Accuracy: 0.7949\n",
      "Epoch 490/512 | Train Loss: 0.4543 | Train Accuracy: 0.8255 | Validation Accuracy: 0.7821\n",
      "Epoch 500/512 | Train Loss: 0.4376 | Train Accuracy: 0.7910 | Validation Accuracy: 0.8141\n",
      "Epoch 510/512 | Train Loss: 0.4248 | Train Accuracy: 0.8223 | Validation Accuracy: 0.7821\n"
     ]
    }
   ],
   "source": [
    "# model = GNN(num_node_features=1, num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0  # Track total number of samples processed\n",
    "    \n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)  # Pass the batch attribute\n",
    "        \n",
    "        loss = loss_func(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        pred = out.argmax(dim=1)  # Get the class with the maximum probability\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)  # Add the size of the current batch to the total\n",
    "\n",
    "    train_acc = correct / total\n",
    "    return total_loss / len(train_loader), train_acc\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0  # Track total number of samples processed\n",
    "    \n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            pred = out.argmax(dim=1)  # Get the class with the maximum probability\n",
    "\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)  # Add the size of the current batch to the total\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "epochs = 512\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train() \n",
    "    val_acc = validate()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f} | Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7580 | Recall: 0.4545 | Precision: 0.5882 | F1 Score: 0.5128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def test_metrics():\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            preds = out.argmax(dim=1).tolist()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(data.y.tolist())\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return acc, recall, precision, f1\n",
    "\n",
    "# At the end of training or wherever you want to print the metrics:\n",
    "acc, recall, precision, f1 = test_metrics()\n",
    "print(f\"Test Accuracy: {acc:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
